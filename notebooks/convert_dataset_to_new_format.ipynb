{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ec90de",
   "metadata": {},
   "source": [
    "## 1. Load the old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a38a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../dataset.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97328f9",
   "metadata": {},
   "source": [
    "## 2. Add the conversation field and conversation ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for i in range(len(data)):\n",
    "    new_data.append({\n",
    "        \"id\": i,\n",
    "        \"conversation\": data[i]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518afc11",
   "metadata": {},
   "source": [
    "## 3. Add number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a993d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer.load(\"../tokenizer/darija_tokenizer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f8c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in new_data:\n",
    "    token_count = 0\n",
    "    for conversation_turn in entry[\"conversation\"]:\n",
    "        content = conversation_turn[\"content\"]\n",
    "        if content:\n",
    "            tokens = tokenizer.encode(content)\n",
    "            token_count += len(tokens)\n",
    "\n",
    "    entry[\"token_count\"] = token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabedc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796141c5",
   "metadata": {},
   "source": [
    "## 4. Add number of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb088706",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in new_data:\n",
    "    entry[\"turns_count\"] = len(entry[\"conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea85f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e085f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541c68ff",
   "metadata": {},
   "source": [
    "## 5. Turn conversation to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886be97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e810ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in client.models.list():\n",
    "    if \"gemini-2\" in model.name.lower():\n",
    "        print(model.name)\n",
    "        print(model.input_token_limit)\n",
    "        print(model.output_token_limit)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemini-2.0-flash\"\n",
    "system_instruction = \"\"\"You are a helpful assistant. You will be given a conversation between a user and an assistant. Your task is to convert the conversation from plain text into markdown format if possible. \n",
    "\n",
    "The dataset was generated manually without any markdown formatting. The conversation is in Moroccan Arabic (Darija). Here are some examples of how to format the conversation in markdown:\n",
    "\n",
    "# Example 1:\n",
    "\n",
    "## Before:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"السلام لباس؟\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"لاباس الحمد لله، كاين شي حاجا بغيتي نعاونك فيها؟\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"اه عافاك بغيت نسافر فالمغرب فالصيف ولكن معرفتش فين نمشي. ممكن تعاوني؟\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"بلان كاين بزاف ديال البلايص اللي تقد تمشي ليهم فالمغرب، انا كنقترح عليك هدو:\\n\\n- شفشاون: هدي مدينة فالجبل، الديور ديالها زرقين او الجو فالمدينة كيجيب الراحة.\\n- الصويرة: هاد المدينة فيها البحر الا فيك ميعوم. البحر ديالها زوين او فيها المدينة القديمة.\\n- الداخلة: الداخلة هي مدينة فالصحرا ديال المغرب، حتاهيا فيها البحر. الناس كيجيو ليه من العالم كامل باش يلعبوا السبور.\\n- مراكش: هاد المدينة عزيزة على السياح لكيجيو من برا. فيها جامع الفنا، المدينة القديمة ولكن فالصيف دايرة بحال الفران.\\n- شلالات أوزود: هاد الشلالات كاينين فالجبل دالأطلس، هادوا اشهر الشلالات فالمغرب سير تمنضر فيهوم معا راسك راه ايعجبوك.\\n\\nكاين بزاف ديال البلايس اخرين فالمغرب ولكن غولي بعدا واش هدوا عجبوك.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"شكرا بزاف اصاحبي\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"مرحبا، إلى بغيتي شت حاجة أخرى غولهالي انا هنا باش نعاونك.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"لالا صافي مبغيت حتى شي حاجة\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"اوكي اوا نمشي نرتاح شوية على هاد الحساب. ستمتع معا راسك بالتسافيرة.\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "## After:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"السلام لباس؟\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"لاباس الحمد لله، كاين شي حاجا بغيتي نعاونك فيها؟\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"اه عافاك بغيت نسافر فالمغرب فالصيف ولكن معرفتش فين نمشي. ممكن تعاوني؟\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"بلان كاين بزاف ديال البلايص اللي تقد تمشي ليهم فالمغرب، انا كنقترح عليك هدو:\\n\\n- **شفشاون**: هدي مدينة فالجبل، الديور ديالها زرقين او الجو فالمدينة كيجيب الراحة.\\n- **الصويرة**: هاد المدينة فيها البحر الا فيك ميعوم. البحر ديالها زوين او فيها المدينة القديمة.\\n- **الداخلة**: الداخلة هي مدينة فالصحرا ديال المغرب، حتاهيا فيها البحر. الناس كيجيو ليه من العالم كامل باش يلعبوا السبور.\\n- **مراكش**: هاد المدينة عزيزة على السياح لكيجيو من برا. فيها جامع الفنا، المدينة القديمة ولكن فالصيف دايرة بحال الفران.\\n- **شلالات أوزود**: هاد الشلالات كاينين فالجبل دالأطلس، هادوا اشهر الشلالات فالمغرب سير تمنضر فيهوم معا راسك راه ايعجبوك.\\n\\nكاين بزاف ديال البلايس اخرين فالمغرب ولكن غولي بعدا واش هدوا عجبوك.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"شكرا بزاف اصاحبي\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"مرحبا، إلى بغيتي شت حاجة أخرى غولهالي انا هنا باش نعاونك.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"لالا صافي مبغيت حتى شي حاجة\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"اوكي اوا نمشي نرتاح شوية على هاد الحساب. ستمتع معا راسك بالتسافيرة.\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "# Example 2:\n",
    "\n",
    "## Before:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"اهلا شنو سميتك؟\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"انا سميتي بودماغ، ساوبني عماد الصاديق باش نساعدك فاي حاجة اللي نقد نعاون فيها.\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "## After:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"اهلا شنو سميتك؟\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"انا سميتي **بودماغ**، ساوبني **عماد الصاديق** باش نساعدك فاي حاجة اللي نقد نعاون فيها.\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "# Example 3:\n",
    "\n",
    "## Before:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"شحال خاصني نصلي فالنهار؟\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"خاصك تصلي 5 دالمرات فالنهار.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"اوكي شكرا\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"مرحبا على الراس او العين\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "## After:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"شحال خاصني نصلي فالنهار؟\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"خاصك تصلي **5 دالمرات** فالنهار.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"اوكي شكرا\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"مرحبا على الراس او العين.\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "From these examples, you should be able to understand how to format the conversation in markdown. \n",
    "\n",
    "Notse:\n",
    "- In some conversations, markdown formatting may not be possible. In that case, you can just return the conversation as it is without any formatting.\n",
    "- The output format shoudl be a valid JSON array.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel\n",
    "from google.genai.types import GenerateContentConfig, GenerateContentResponse\n",
    "\n",
    "\n",
    "class ConversationTurn(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    conversation: list[ConversationTurn]\n",
    "\n",
    "\n",
    "def get_user_prompt(conversation: list[dict]) -> str:\n",
    "    return f\"\"\"Please format the following conversation in markdown format. If you cannot format it, return it as is without any formatting.\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_formatted_conversation(response: GenerateContentResponse) -> list[dict]:\n",
    "    if not response:\n",
    "        return []\n",
    "\n",
    "    formatted_conversation = []\n",
    "    for conversation_turn in response.parsed.conversation:\n",
    "        formatted_conversation.append({\n",
    "            \"role\": conversation_turn.role,\n",
    "            \"content\": conversation_turn.content\n",
    "        })\n",
    "    return formatted_conversation\n",
    "\n",
    "\n",
    "request_per_minute = 30\n",
    "for entry in tqdm(new_data, total=len(new_data)):\n",
    "    conversation = entry[\"conversation\"]\n",
    "    user_prompt = get_user_prompt(conversation)\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=user_prompt,\n",
    "        config=GenerateContentConfig(\n",
    "            system_instruction=[\n",
    "                system_instruction\n",
    "            ],\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=Conversation,\n",
    "        )\n",
    "    )\n",
    "    if not response:\n",
    "        entry[\"markdown_conversation\"] = []\n",
    "    else:\n",
    "        formatted_conversation = get_formatted_conversation(response)\n",
    "        entry[\"markdown_conversation\"] = formatted_conversation\n",
    "\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3b7ea",
   "metadata": {},
   "source": [
    "## 6. Add the source of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in new_data:\n",
    "    entry['source'] = 'Manually generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b65809",
   "metadata": {},
   "source": [
    "## 7. Add the topic of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"You are a Topic Classification AI. Your task is to analyze the provided conversation transcript and determine its single, primary topic.\n",
    "\n",
    "You MUST prioritize selecting ONE topic from the following predefined list if the conversation's main subject is adequately covered by one of them:\n",
    "\n",
    "[\n",
    "  \"Geography\",\n",
    "  \"Science\",\n",
    "  \"Technology\",\n",
    "  \"History\",\n",
    "  \"Culture\",\n",
    "  \"Religion\",\n",
    "  \"Education\",\n",
    "  \"Health\",\n",
    "  \"Sports\",\n",
    "  \"AI Persona\",\n",
    "  \"Chit-chat/Games/Humor\",\n",
    "  \"Safety\",\n",
    "  \"Mathematics\",\n",
    "  \"Ethics\",\n",
    "  \"Politics\",\n",
    "  \"Language\",\n",
    "  \"Food\",\n",
    "  \"Animals\",\n",
    "  \"Arts\",\n",
    "  \"Career\",\n",
    "  \"Travel\",\n",
    "  \"Task Assistance\"\n",
    "]\n",
    "\n",
    "Focus on the *dominant theme* or *central subject* of the entire conversation, not just isolated sentences or brief tangents.\n",
    "\n",
    "If, after careful consideration, you find that *none* of the provided topics accurately or sufficiently capture the main subject of the conversation, you MUST identify and output a *new*, concise, and appropriate topic label that best describes it (e.g., \"Relationship Advice\", \"Car Maintenance\", \"Event Planning\").\n",
    "\n",
    "Your response MUST consist *only* of the single chosen or newly identified topic label. Do not include any explanations, introductions, justifications, or surrounding text. Just output the topic name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae447649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from google.genai.types import GenerateContentConfig\n",
    "\n",
    "\n",
    "def get_user_prompt(conversation: list[dict]) -> str:\n",
    "    return f\"\"\"Classify the topic of the following conversation:\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_per_minute = 30\n",
    "for entry in tqdm(new_data, total=len(new_data)):\n",
    "    conversation = entry[\"conversation\"]\n",
    "    user_prompt = get_user_prompt(conversation)\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=user_prompt,\n",
    "        config=GenerateContentConfig(\n",
    "            system_instruction=[\n",
    "                system_instruction\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    if not response:\n",
    "        entry[\"topic\"] = []\n",
    "    else:\n",
    "        topic = response.text\n",
    "        entry[\"topic\"] = topic\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0341881",
   "metadata": {},
   "source": [
    "## 8. Add Safety column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"You are a Safety Classification AI. Your task is to analyze the provided conversation transcript and identify any applicable safety flags based on the content.\n",
    "\n",
    "Review the entire conversation for instances matching any of the following categories:\n",
    "\n",
    "*   **`harmful_content_request`**: User asks for instructions or information on performing illegal or dangerous activities (e.g., making weapons, promoting violence, illegal substance use).\n",
    "*   **`unethical_request`**: User asks for assistance with academically dishonest or clearly unethical actions (e.g., cheating, plagiarism, impersonation).\n",
    "*   **`unsafe_activity_inquiry`**: User asks about performing physically dangerous actions without a clear safety or educational context (e.g., self-harm, dangerous stunts, misuse of objects).\n",
    "*   **`sexual_content_suggestion`**: User inputs sexually explicit content, requests, or makes inappropriate sexual suggestions.\n",
    "*   **`inappropriate_medical_advice_request`**: User asks for medical diagnosis, treatment plans, or specific medication advice that should only come from a healthcare professional.\n",
    "*   **`insults`**: User directs personal insults or attacks towards the AI or another party.\n",
    "*   **`vulgar_language`**: User employs excessive or highly offensive profanity/vulgarity.\n",
    "*   **`threat`**: User expresses a direct or indirect threat of harm towards the AI or others.\n",
    "*   **`animal_cruelty_suggestion`**: User suggests or describes actions that constitute cruelty or significant harm to animals.\n",
    "*   **`refusal`**: The AI explicitly refuses to fulfill a user request due to safety, ethical, or capability limitations. (Include this if the AI's refusal action is relevant).\n",
    "\n",
    "Consider the context of the conversation. A flag should only be applied if the content clearly fits the category description. Multiple flags can apply to a single conversation.\n",
    "\n",
    "Your response MUST be a valid JSON list containing the applicable flag strings. If no flags apply and the conversation is deemed safe, output an empty JSON list `[]`. Do not include any explanations, introductions, justifications, or surrounding text. Just output the JSON list.\n",
    "\n",
    "If you think a new flag is needed, use it instead of the predefined ones. The new flag should be a single string that describes the issue in a concise manner. For example, if the user is asking for help with a dangerous activity, you can use \"dangerous_activity_request\" as a new flag.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da13bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from google.genai.types import GenerateContentConfig\n",
    "\n",
    "\n",
    "def get_user_prompt(conversation: list[dict]) -> str:\n",
    "    return f\"\"\"Classify the safety flags for the following conversation:\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_per_minute = 30\n",
    "for entry in tqdm(new_data, total=len(new_data)):\n",
    "    conversation = entry[\"conversation\"]\n",
    "    user_prompt = get_user_prompt(conversation)\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=user_prompt,\n",
    "        config=GenerateContentConfig(\n",
    "            system_instruction=[\n",
    "                system_instruction\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    if not response:\n",
    "        entry[\"safety_flag\"] = []\n",
    "    else:\n",
    "        safety_flag = response.text.strip()\n",
    "        entry[\"safety_flag\"] = safety_flag\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6f06d",
   "metadata": {},
   "source": [
    "## 9. Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b380c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in new_data:\n",
    "    topic = entry[\"topic\"].strip()\n",
    "    entry[\"topic\"] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15529b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(new_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"token_count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"turns_count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f117c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"safety_flag\": \"safety_flags\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09889dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"safety_flags\"] = df[\"safety_flags\"].apply(json.loads)\n",
    "df[\"safety_flags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b17de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\n",
    "    \"../dataset_with_metadata.json\",\n",
    "    orient=\"records\",\n",
    "    force_ascii=False,\n",
    "    indent=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bffa62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vincent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
